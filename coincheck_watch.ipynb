{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bita46a4a11000847309cdd4e52c21c0e11",
   "display_name": "Python 3.7.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from binance.client import Client\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from libs import *\n",
    "from utils import *\n",
    "\n",
    "with open(\"C:\\\\Users\\\\thang\\\\OneDrive\\\\Documents\\\\binance_cres\\\\api_key.txt\") as api_file:\n",
    "    api_key = api_file.readline()\n",
    "with open(\"C:\\\\Users\\\\thang\\\\OneDrive\\\\Documents\\\\binance_cres\\\\sec_key.txt\") as api_file:\n",
    "    api_secret = api_file.readline()\n",
    "# make binance object\n",
    "client = Client(api_key, api_secret)\n",
    "\n",
    "# Parameters\n",
    "target_coin = 'ETCUSDT'\n",
    "BATCH_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[name] = value\nc:\\Users\\thang\\Documents\\pred_coin_price\\ts_pred_viz\\utils.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['Day sin'] = np.sin(date_time * (2 * np.pi / day))\nc:\\Users\\thang\\Documents\\pred_coin_price\\ts_pred_viz\\utils.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['Day cos'] = np.cos(date_time * (2 * np.pi / day))\nc:\\Users\\thang\\Documents\\pred_coin_price\\ts_pred_viz\\utils.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['Year sin'] = np.sin(date_time * (2 * np.pi / year))\nc:\\Users\\thang\\Documents\\pred_coin_price\\ts_pred_viz\\utils.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['Year cos'] = np.cos(date_time * (2 * np.pi / year))\n"
     ]
    }
   ],
   "source": [
    "avg_data = client.get_klines(symbol=target_coin, interval=Client.KLINE_INTERVAL_30MINUTE)\n",
    "cols = ['open_time',  # Open time\n",
    "            'open',  # Open\n",
    "            'high',  # High\n",
    "            'low',  # Low\n",
    "            'close',  # Close\n",
    "            'vol',  # Volume\n",
    "            'close_time',  # Close time\n",
    "            'quote_ass_vol',  # Quote asset volume\n",
    "            'no_trade',  # Number of trades\n",
    "            'base_ass_vol',  # Taker buy base asset volume\n",
    "            'qoute_ass_vol',  # Taker buy quote asset volume\n",
    "            'ignore']   # Can be ignored\n",
    "df = pd.DataFrame(avg_data, \n",
    "    columns = cols)\n",
    "\n",
    "important_features_df = df[['close','close_time','vol']]  # get important features\n",
    "important_features_df.close_time = important_features_df.close_time.apply(lambda x: x/1000)  # convert milisecond to second\n",
    "important_features_df = data_converter(important_features_df)  # conver time data to sequence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            close            vol       Day sin       Day cos    Year sin  \\\n",
       "count  500.000000     500.000000  5.000000e+02  5.000000e+02  500.000000   \n",
       "mean    69.523928  120573.218212  2.220755e-02 -1.947549e-02    0.545978   \n",
       "std      5.915375  112134.479067  7.078198e-01  7.071923e-01    0.043328   \n",
       "min     50.242000    5947.546000 -1.000000e+00 -1.000000e+00    0.469753   \n",
       "25%     66.418250   52243.275500 -7.071067e-01 -7.071068e-01    0.508739   \n",
       "50%     68.461500   81971.408500  7.272471e-08 -7.272264e-08    0.546709   \n",
       "75%     74.585500  140971.471500  7.071068e-01  7.071067e-01    0.583587   \n",
       "max     82.197000  915454.300000  1.000000e+00  1.000000e+00    0.619297   \n",
       "\n",
       "         Year cos  \n",
       "count  500.000000  \n",
       "mean    -0.836203  \n",
       "std      0.028304  \n",
       "min     -0.882798  \n",
       "25%     -0.860921  \n",
       "50%     -0.837323  \n",
       "75%     -0.812051  \n",
       "max     -0.785156  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close</th>\n      <th>vol</th>\n      <th>Day sin</th>\n      <th>Day cos</th>\n      <th>Year sin</th>\n      <th>Year cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>500.000000</td>\n      <td>500.000000</td>\n      <td>5.000000e+02</td>\n      <td>5.000000e+02</td>\n      <td>500.000000</td>\n      <td>500.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>69.523928</td>\n      <td>120573.218212</td>\n      <td>2.220755e-02</td>\n      <td>-1.947549e-02</td>\n      <td>0.545978</td>\n      <td>-0.836203</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>5.915375</td>\n      <td>112134.479067</td>\n      <td>7.078198e-01</td>\n      <td>7.071923e-01</td>\n      <td>0.043328</td>\n      <td>0.028304</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>50.242000</td>\n      <td>5947.546000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000e+00</td>\n      <td>0.469753</td>\n      <td>-0.882798</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>66.418250</td>\n      <td>52243.275500</td>\n      <td>-7.071067e-01</td>\n      <td>-7.071068e-01</td>\n      <td>0.508739</td>\n      <td>-0.860921</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>68.461500</td>\n      <td>81971.408500</td>\n      <td>7.272471e-08</td>\n      <td>-7.272264e-08</td>\n      <td>0.546709</td>\n      <td>-0.837323</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>74.585500</td>\n      <td>140971.471500</td>\n      <td>7.071068e-01</td>\n      <td>7.071067e-01</td>\n      <td>0.583587</td>\n      <td>-0.812051</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>82.197000</td>\n      <td>915454.300000</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.619297</td>\n      <td>-0.785156</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "important_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "# column_indices = {name: i for i, name in enumerate(important_features_df.columns)}\n",
    "\n",
    "n = len(important_features_df)\n",
    "train_df = important_features_df[0:int(n*0.7)]  # 70% train data\n",
    "val_df = important_features_df[int(n*0.7):int(n*0.9)]  # 20% val data\n",
    "test_df = important_features_df[int(n*0.9):]  # 10% test data\n",
    "\n",
    "num_features = important_features_df.shape[1]  # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "# normalize base on train_data distribution\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_predictors = 24  # number of historical data as predictor\n",
    "time_shift = 24  # number of timestamp to target\n",
    "label_width = 1  # number of predicting timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Total window size: 48\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
       "Label indices: [47]\n",
       "Label column name(s): ['close']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# prepare data\n",
    "single_step_window = WindowGenerator(\n",
    "    input_width=time_predictors, label_width=label_width, shift=time_shift, train_df=train_df, val_df=val_df, test_df=test_df, label_columns=['close'])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n(32, 24, 6)\n2\n(32, 24, 6)\n3\n(32, 24, 6)\n4\n(32, 24, 6)\n5\n(32, 24, 6)\n6\n(32, 24, 6)\n7\n(32, 24, 6)\n8\n(32, 24, 6)\n9\n(32, 24, 6)\n10\n(15, 24, 6)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for element in single_step_window.train[0]:\n",
    "    count += 1\n",
    "    # print(count)\n",
    "    # print(element.numpy().shape)\n",
    "    if len(element.numpy()) < BATCH_SIZE:\n",
    "        break\n",
    "    if count == 1:\n",
    "        train_input = element.numpy()\n",
    "    else:\n",
    "        train_input = np.append(train_input, element.numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for element in single_step_window.train[1]:\n",
    "    count += 1\n",
    "    # print(count)\n",
    "    # print(element.numpy().shape)\n",
    "    if len(element.numpy()) < BATCH_SIZE:\n",
    "        break\n",
    "    if count == 1:\n",
    "        train_label = element.numpy()\n",
    "    else:\n",
    "        train_label = np.append(train_label, element.numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(288, 24, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(288, 1, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main model ###\n",
    "# linear module\n",
    "linear_input = tf.keras.Input(shape=(single_step_window.example[0].shape[1:]), batch_size=BATCH_SIZE)  # batch 32 input shape = 24,6\n",
    "x = tf.keras.layers.Flatten()(linear_input)\n",
    "x = tf.keras.layers.Dense(units=128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=1, activation='relu')(x)\n",
    "linear_model = tf.keras.Model(inputs=linear_input, outputs=x)  # output = 32,1\n",
    "\n",
    "# lstm module\n",
    "lstm_input = tf.keras.Input(shape=(single_step_window.example[0].shape[1:]), batch_size=BATCH_SIZE)\n",
    "y = tf.keras.layers.LSTM(32, return_sequences=False)(lstm_input)\n",
    "y = tf.keras.layers.Dense(units=1, activation='relu')(y)\n",
    "lstm_model = tf.keras.Model(inputs=lstm_input, outputs=y)  # output = 32,1\n",
    "\n",
    "# intersection\n",
    "z = tf.keras.layers.concatenate([linear_model.output, lstm_model.output])\n",
    "z = tf.keras.layers.Dense(units=64, activation='relu')(z)\n",
    "z = tf.keras.layers.Dense(units=1, activation='relu')(z)\n",
    "comb_model = tf.keras.Model(inputs=[linear_input, lstm_input], outputs=[z])\n",
    "\n",
    "\n",
    "# training setting\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "def compile_and_fit(model, train_input, train_label, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                  patience=2,\n",
    "                                                  mode='min')\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "  model.summary()\n",
    "\n",
    "  history = comb_model.fit([train_input, train_input], [train_label], epochs=MAX_EPOCHS )\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(comb_model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(32, 24, 6)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (32, 144)            0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (32, 128)            18560       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(32, 24, 6)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (32, 64)             8256        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (32, 32)             4992        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (32, 1)              65          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (32, 1)              33          lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (32, 2)              0           dense_8[0][0]                    \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (32, 64)             192         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (32, 1)              65          dense_10[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 32,163\n",
      "Trainable params: 32,163\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7234 - mean_absolute_error: 0.7576\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7091 - mean_absolute_error: 0.7460\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7014 - mean_absolute_error: 0.7422\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7002 - mean_absolute_error: 0.7449\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6916 - mean_absolute_error: 0.7333\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6856 - mean_absolute_error: 0.7335\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6817 - mean_absolute_error: 0.7216\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6745 - mean_absolute_error: 0.7258\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6716 - mean_absolute_error: 0.7141\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6612 - mean_absolute_error: 0.7129\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6523 - mean_absolute_error: 0.7015\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6579 - mean_absolute_error: 0.7012\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6656 - mean_absolute_error: 0.7177\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6427 - mean_absolute_error: 0.6902\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6553 - mean_absolute_error: 0.7090\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6494 - mean_absolute_error: 0.6974\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6277 - mean_absolute_error: 0.6885\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6222 - mean_absolute_error: 0.6862\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.6160 - mean_absolute_error: 0.6741\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6196 - mean_absolute_error: 0.6842\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x249dec99c08>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "compile_and_fit(comb_model, train_input, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 0.5946 - mean_absolute_error: 0.6675\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5946 - mean_absolute_error: 0.6675\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['multi_modal'] = comb_model.evaluate([train_input, train_input], [train_label])\n",
    "performance['multi_modal'] = comb_model.evaluate([train_input, train_input], [train_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'multi_modal': [0.5946481227874756, 0.6674641966819763]}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "val_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(train_df.columns)),\n",
    "        height=lstm_model.layers[0].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns)))\n",
    "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', linear(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}