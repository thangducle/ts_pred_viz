{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bita46a4a11000847309cdd4e52c21c0e11",
   "display_name": "Python 3.7.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from binance.client import Client\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from libs import *\n",
    "from utils import *\n",
    "\n",
    "with open(\"C:\\\\Users\\\\thang\\\\OneDrive\\\\Documents\\\\binance_cres\\\\api_key.txt\") as api_file:\n",
    "    api_key = api_file.readline()\n",
    "with open(\"C:\\\\Users\\\\thang\\\\OneDrive\\\\Documents\\\\binance_cres\\\\sec_key.txt\") as api_file:\n",
    "    api_secret = api_file.readline()\n",
    "# make binance object\n",
    "client = Client(api_key, api_secret)\n",
    "\n",
    "# Parameters\n",
    "target_coin = 'ETCUSDT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Raw data\n",
    "# agg_trades = client.aggregate_trade_iter(symbol='ETCUSDT', start_str='60 minutes ago UTC')\n",
    "\n",
    "# # iterate over the trade iterator\n",
    "# df_dict = {'a':[], 'p':[], 'q':[], 'f':[], 'l':[],'T':[], 'm':[],'M':[]}\n",
    "# for trade in agg_trades:\n",
    "#     # prices.append(trade[\"p\"])\n",
    "#     df_dict['a'].append(trade[\"a\"])\n",
    "#     df_dict['p'].append(trade[\"p\"])\n",
    "#     df_dict['q'].append(trade[\"q\"])\n",
    "#     df_dict['f'].append(trade[\"f\"])\n",
    "#     df_dict['l'].append(trade[\"l\"])\n",
    "#     df_dict['T'].append(trade[\"T\"])\n",
    "#     df_dict['m'].append(trade[\"m\"])\n",
    "#     df_dict['M'].append(trade[\"M\"])\n",
    "#     print(trade)\n",
    "\n",
    "# df = pd.DataFrame.from_dict(df_dict)\n",
    "# interested_df = df[['p','q','T']]  # get price as p, quantity as q, Time as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_data = client.get_klines(symbol=target_coin, interval=Client.KLINE_INTERVAL_30MINUTE)\n",
    "cols = ['open_time',  # Open time\n",
    "            'open',  # Open\n",
    "            'high',  # High\n",
    "            'low',  # Low\n",
    "            'close',  # Close\n",
    "            'vol',  # Volume\n",
    "            'close_time',  # Close time\n",
    "            'quote_ass_vol',  # Quote asset volume\n",
    "            'no_trade',  # Number of trades\n",
    "            'base_ass_vol',  # Taker buy base asset volume\n",
    "            'qoute_ass_vol',  # Taker buy quote asset volume\n",
    "            'ignore']   # Can be ignored\n",
    "df = pd.DataFrame(avg_data, \n",
    "    columns = cols)\n",
    "\n",
    "important_features_df = df[['close','close_time','vol']]  # get important features\n",
    "important_features_df.close_time = important_features_df.close_time.apply(lambda x: x/1000)  # convert milisecond to second\n",
    "important_features_df = data_converter(important_features_df)  # conver time data to sequence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "# column_indices = {name: i for i, name in enumerate(important_features_df.columns)}\n",
    "\n",
    "n = len(important_features_df)\n",
    "train_df = important_features_df[0:int(n*0.7)]  # 70% train data\n",
    "val_df = important_features_df[int(n*0.7):int(n*0.9)]  # 20% val data\n",
    "test_df = important_features_df[int(n*0.9):]  # 10% test data\n",
    "\n",
    "num_features = important_features_df.shape[1]  # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "# normalize base on train_data distribution\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_predictors = 24  # number of historical data as predictor\n",
    "time_shift = 24  # number of timestamp to target\n",
    "label_width = 1  # number of predicting timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "single_step_window = WindowGenerator(\n",
    "    input_width=time_predictors, label_width=label_width, shift=time_shift, train_df=train_df, val_df=val_df, test_df=test_df, label_columns=['close'])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window.example[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main model ###\n",
    "# linear module\n",
    "linear_input = tf.keras.Input(shape=(single_step_window.example[0].shape[1:]), batch_size=single_step_window.example[0].shape[0])  # batch 32 input shape = 24,6\n",
    "x = tf.keras.layers.Flatten()(linear_input)\n",
    "x = tf.keras.layers.Dense(units=64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=1, activation='relu')(x)\n",
    "linear_model = tf.keras.Model(inputs=linear_input, outputs=x)  # output = 32,1\n",
    "\n",
    "# lstm module\n",
    "lstm_input = tf.keras.Input(shape=(single_step_window.example[0].shape[1:]), batch_size=single_step_window.example[0].shape[0])\n",
    "y = tf.keras.layers.LSTM(32, return_sequences=False)(lstm_input)\n",
    "y = tf.keras.layers.Dense(units=1, activation='relu')(y)\n",
    "lstm_model = tf.keras.Model(inputs=lstm_input, outputs=y)  # output = 32,1\n",
    "\n",
    "# intersection\n",
    "z = tf.keras.layers.concatenate([linear_model.output, lstm_model.output])\n",
    "z = tf.keras.layers.Dense(units=64, activation='relu')(z)\n",
    "z = tf.keras.layers.Dense(units=1, activation='relu')(z)\n",
    "comb_model = tf.keras.Model(inputs=[linear_input, lstm_input], outputs=[z])\n",
    "\n",
    "\n",
    "# training setting\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = compile_and_fit(linear, single_step_window)\n",
    "# linear.summary()\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['Linear'] = linear.evaluate(single_step_window.val)\n",
    "performance['Linear'] = linear.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_step_window.plot(linear, max_subplots=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(train_df.columns)),\n",
    "        height=lstm_model.layers[0].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns)))\n",
    "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', linear(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}