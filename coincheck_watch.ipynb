{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37564bita46a4a11000847309cdd4e52c21c0e11",
   "display_name": "Python 3.7.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from binance.client import Client\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime\n",
    "from libs import *\n",
    "from utils import *\n",
    "\n",
    "with open(\"C:\\\\Users\\\\thang\\\\OneDrive\\\\Documents\\\\binance_cres\\\\api_key.txt\") as api_file:\n",
    "    api_key = api_file.readline()\n",
    "with open(\"C:\\\\Users\\\\thang\\\\OneDrive\\\\Documents\\\\binance_cres\\\\sec_key.txt\") as api_file:\n",
    "    api_secret = api_file.readline()\n",
    "# make binance object\n",
    "client = Client(api_key, api_secret)\n",
    "\n",
    "# Parameters\n",
    "target_coin = 'ETCUSDT'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Raw data\n",
    "# agg_trades = client.aggregate_trade_iter(symbol='ETCUSDT', start_str='60 minutes ago UTC')\n",
    "\n",
    "# # iterate over the trade iterator\n",
    "# df_dict = {'a':[], 'p':[], 'q':[], 'f':[], 'l':[],'T':[], 'm':[],'M':[]}\n",
    "# for trade in agg_trades:\n",
    "#     # prices.append(trade[\"p\"])\n",
    "#     df_dict['a'].append(trade[\"a\"])\n",
    "#     df_dict['p'].append(trade[\"p\"])\n",
    "#     df_dict['q'].append(trade[\"q\"])\n",
    "#     df_dict['f'].append(trade[\"f\"])\n",
    "#     df_dict['l'].append(trade[\"l\"])\n",
    "#     df_dict['T'].append(trade[\"T\"])\n",
    "#     df_dict['m'].append(trade[\"m\"])\n",
    "#     df_dict['M'].append(trade[\"M\"])\n",
    "#     print(trade)\n",
    "\n",
    "# df = pd.DataFrame.from_dict(df_dict)\n",
    "# interested_df = df[['p','q','T']]  # get price as p, quantity as q, Time as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Python37_64\\lib\\site-packages\\pandas\\core\\generic.py:5494: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self[name] = value\nc:\\Users\\thang\\Documents\\pred_coin_price\\ts_pred_viz\\utils.py:12: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['Day sin'] = np.sin(date_time * (2 * np.pi / day))\nc:\\Users\\thang\\Documents\\pred_coin_price\\ts_pred_viz\\utils.py:13: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['Day cos'] = np.cos(date_time * (2 * np.pi / day))\nc:\\Users\\thang\\Documents\\pred_coin_price\\ts_pred_viz\\utils.py:14: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['Year sin'] = np.sin(date_time * (2 * np.pi / year))\nc:\\Users\\thang\\Documents\\pred_coin_price\\ts_pred_viz\\utils.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df['Year cos'] = np.cos(date_time * (2 * np.pi / year))\n"
     ]
    }
   ],
   "source": [
    "avg_data = client.get_klines(symbol=target_coin, interval=Client.KLINE_INTERVAL_30MINUTE)\n",
    "cols = ['open_time',  # Open time\n",
    "            'open',  # Open\n",
    "            'high',  # High\n",
    "            'low',  # Low\n",
    "            'close',  # Close\n",
    "            'vol',  # Volume\n",
    "            'close_time',  # Close time\n",
    "            'quote_ass_vol',  # Quote asset volume\n",
    "            'no_trade',  # Number of trades\n",
    "            'base_ass_vol',  # Taker buy base asset volume\n",
    "            'qoute_ass_vol',  # Taker buy quote asset volume\n",
    "            'ignore']   # Can be ignored\n",
    "df = pd.DataFrame(avg_data, \n",
    "    columns = cols)\n",
    "\n",
    "important_features_df = df[['close','close_time','vol']]  # get important features\n",
    "important_features_df.close_time = important_features_df.close_time.apply(lambda x: x/1000)  # convert milisecond to second\n",
    "important_features_df = data_converter(important_features_df)  # conver time data to sequence vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "            close            vol       Day sin       Day cos    Year sin  \\\n",
       "count  500.000000     500.000000  5.000000e+02  5.000000e+02  500.000000   \n",
       "mean    67.835704  137950.289270  2.220755e-02 -1.947549e-02    0.560282   \n",
       "std      8.080250  122763.196009  7.078198e-01  7.071923e-01    0.042835   \n",
       "min     42.432000    8626.440000 -1.000000e+00 -1.000000e+00    0.484869   \n",
       "25%     64.444000   56875.791250 -7.071067e-01 -7.071068e-01    0.523473   \n",
       "50%     67.748000   97151.412000  7.272603e-08 -7.272430e-08    0.561032   \n",
       "75%     74.585500  171530.258000  7.071068e-01  7.071067e-01    0.597469   \n",
       "max     82.197000  915454.300000  1.000000e+00  1.000000e+00    0.632712   \n",
       "\n",
       "         Year cos  \n",
       "count  500.000000  \n",
       "mean    -0.826687  \n",
       "std      0.029044  \n",
       "min     -0.874587  \n",
       "25%     -0.852042  \n",
       "50%     -0.827794  \n",
       "75%     -0.801892  \n",
       "max     -0.774387  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close</th>\n      <th>vol</th>\n      <th>Day sin</th>\n      <th>Day cos</th>\n      <th>Year sin</th>\n      <th>Year cos</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>500.000000</td>\n      <td>500.000000</td>\n      <td>5.000000e+02</td>\n      <td>5.000000e+02</td>\n      <td>500.000000</td>\n      <td>500.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>67.835704</td>\n      <td>137950.289270</td>\n      <td>2.220755e-02</td>\n      <td>-1.947549e-02</td>\n      <td>0.560282</td>\n      <td>-0.826687</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.080250</td>\n      <td>122763.196009</td>\n      <td>7.078198e-01</td>\n      <td>7.071923e-01</td>\n      <td>0.042835</td>\n      <td>0.029044</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>42.432000</td>\n      <td>8626.440000</td>\n      <td>-1.000000e+00</td>\n      <td>-1.000000e+00</td>\n      <td>0.484869</td>\n      <td>-0.874587</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>64.444000</td>\n      <td>56875.791250</td>\n      <td>-7.071067e-01</td>\n      <td>-7.071068e-01</td>\n      <td>0.523473</td>\n      <td>-0.852042</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>67.748000</td>\n      <td>97151.412000</td>\n      <td>7.272603e-08</td>\n      <td>-7.272430e-08</td>\n      <td>0.561032</td>\n      <td>-0.827794</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>74.585500</td>\n      <td>171530.258000</td>\n      <td>7.071068e-01</td>\n      <td>7.071067e-01</td>\n      <td>0.597469</td>\n      <td>-0.801892</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>82.197000</td>\n      <td>915454.300000</td>\n      <td>1.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>0.632712</td>\n      <td>-0.774387</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "important_features_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "# column_indices = {name: i for i, name in enumerate(important_features_df.columns)}\n",
    "\n",
    "n = len(important_features_df)\n",
    "train_df = important_features_df[0:int(n*0.7)]  # 70% train data\n",
    "val_df = important_features_df[int(n*0.7):int(n*0.9)]  # 20% val data\n",
    "test_df = important_features_df[int(n*0.9):]  # 10% test data\n",
    "\n",
    "num_features = important_features_df.shape[1]  # number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "# normalize base on train_data distribution\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "val_df = (val_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_predictors = 24  # number of historical data as predictor\n",
    "time_shift = 24  # number of timestamp to target\n",
    "label_width = 1  # number of predicting timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def input_windows_maker(data_matrix):\n",
    "#     inputs = data_matrix[:, :24, :]\n",
    "#     return inputs\n",
    "\n",
    "# def output_windows_maker(data_matrix):\n",
    "#     inputs = data_matrix[:, 24:, :]\n",
    "#     return inputs\n",
    "# ds_output = ds.map(output_windows_maker)\n",
    "# for k in ds_output:\n",
    "#     print(k.numpy().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Total window size: 48\n",
       "Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23]\n",
       "Label indices: [47]\n",
       "Label column name(s): ['close']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# prepare data\n",
    "single_step_window = WindowGenerator(\n",
    "    input_width=time_predictors, label_width=label_width, shift=time_shift, train_df=train_df, val_df=val_df, test_df=test_df, label_columns=['close'])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2947313e-01 -4.6015212e-01]\n  [ 6.4674383e-01 -8.6104244e-01 -1.4479913e+00  1.5867855e-02\n   -4.3947282e-01 -4.6981344e-01]\n  [ 6.6573018e-01 -8.5704416e-01 -1.4359971e+00  2.0178506e-01\n   -4.4947499e-01 -4.7946972e-01]]\n\n [[ 5.8988911e-01  8.3466512e-01  9.4533896e-01  1.0230476e+00\n    8.0049467e-01  7.8641087e-01]\n  [ 4.9297521e-01  2.2137575e+00  1.0662550e+00  8.8296771e-01\n    7.9081559e-01  7.7613539e-01]\n  [ 6.5696728e-01  6.6279739e-01  1.1681397e+00  7.2805154e-01\n    7.8113389e-01  7.6586479e-01]\n  ...\n  [ 1.1748149e+00  2.3635588e+00 -5.8252537e-01 -1.3000757e+00\n    5.9668088e-01  5.7164294e-01]\n  [ 9.1609973e-01  2.0526426e+00 -7.4700093e-01 -1.2176701e+00\n    5.8694655e-01  5.6146926e-01]\n  [ 1.0323129e+00  9.5657992e-01 -8.9948231e-01 -1.1141584e+00\n    5.7720965e-01  5.5130041e-01]]\n\n [[-2.3768653e-01 -1.7167050e-01  1.3698444e-01 -1.3963134e+00\n   -7.9101825e-01 -8.0480450e-01]\n  [-3.7758049e-01  4.1336939e-01 -4.6010718e-02 -1.4084990e+00\n   -8.0110657e-01 -8.1428528e-01]\n  [ 4.4292159e-02  6.2479359e-01 -2.2900587e-01 -1.3963134e+00\n   -8.1119734e-01 -8.2376099e-01]\n  ...\n  [-1.8740398e-01 -3.9982814e-01 -7.4700111e-01  1.2494060e+00\n   -1.0033836e+00 -1.0028412e+00]\n  [-1.4494547e-01 -5.4754376e-01 -5.8252555e-01  1.3318114e+00\n   -1.0135229e+00 -1.0122160e+00]\n  [-9.2054911e-02 -9.2626071e-01 -4.0887013e-01  1.3917009e+00\n   -1.0236646e+00 -1.0215857e+00]]\n\n ...\n\n [[ 9.1443062e-01 -8.3035409e-01 -1.4002199e+00  3.8452116e-01\n    1.7920269e-02 -2.0245951e-02]\n  [ 8.5768014e-01 -7.4138439e-01 -1.3412719e+00  5.6094950e-01\n    8.0337245e-03 -3.0130645e-02]\n  [ 9.3571198e-01 -7.2986734e-01 -1.2601615e+00  7.2805136e-01\n   -1.8553628e-03 -4.0010408e-02]\n  ...\n  [ 5.8498603e-01 -8.0212516e-01  1.3439754e+00  2.0178527e-01\n   -1.9022939e-01 -2.2678620e-01]\n  [ 7.4605709e-01 -7.4221879e-01  1.3559695e+00  1.5868064e-02\n   -2.0016904e-01 -2.3656696e-01]\n  [ 7.1330041e-01 -9.1017908e-01  1.3439754e+00 -1.7004915e-01\n   -2.1011123e-01 -2.4634276e-01]]\n\n [[-1.1760507e+00 -5.4007006e-01  1.2492502e+00 -5.2921361e-01\n    1.6323161e+00  1.6987252e+00]\n  [-1.1978537e+00 -8.0332663e-03  1.1681398e+00 -6.9631547e-01\n    1.6228718e+00  1.6880344e+00]\n  [-1.3034261e+00  7.4614418e-01  1.0662551e+00 -8.5123163e-01\n    1.6134245e+00  1.6773484e+00]\n  ...\n  [-2.3323405e+00  5.7863545e-01 -1.4479913e+00  1.5867855e-02\n    1.4334077e+00  1.4752103e+00]\n  [-2.3130412e+00  1.0020280e+00 -1.4359971e+00  2.0178506e-01\n    1.4239057e+00  1.4646188e+00]\n  [-2.4075558e+00  5.2693075e-01 -1.4002199e+00  3.8452116e-01\n    1.4144011e+00  1.4540321e+00]]\n\n [[ 7.7318043e-01 -3.9603835e-01 -1.1582766e+00 -8.5123181e-01\n   -3.8949925e-01 -4.2145702e-01]\n  [ 8.1386548e-01 -7.0512527e-01 -1.2601614e+00 -6.9631565e-01\n   -3.9948899e-01 -4.3113828e-01]\n  [ 6.3662475e-01 -2.9743937e-01 -1.3412718e+00 -5.2921379e-01\n   -4.0948120e-01 -4.4081455e-01]\n  ...\n  [ 8.5016906e-01 -4.0737477e-01  6.5497929e-01  1.2494060e+00\n   -5.9980494e-01 -6.2371433e-01]\n  [ 8.5288143e-01 -5.9221566e-01  8.0746067e-01  1.1458944e+00\n   -6.0984671e-01 -6.3329059e-01]\n  [ 8.6331350e-01 -7.6264167e-01  9.4533896e-01  1.0230476e+00\n   -6.1989093e-01 -6.4286184e-01]]]\n6\n[[[-1.9504228e+00  1.2334487e-01 -2.2900587e-01 -1.3963134e+00\n    1.5377485e+00  1.5920295e+00]\n  [-2.1268289e+00  2.4589159e+00 -4.0886995e-01 -1.3599650e+00\n    1.5282766e+00  1.5813860e+00]\n  [-2.1577079e+00  3.4756191e+00 -5.8252537e-01 -1.3000757e+00\n    1.5188019e+00  1.5707470e+00]\n  ...\n  [-1.8131368e+00  4.4397312e-01 -4.0887013e-01  1.3917009e+00\n    1.3382661e+00  1.3695091e+00]\n  [-1.6813798e+00 -7.6650701e-02 -2.2900608e-01  1.4280493e+00\n    1.3287370e+00  1.3589650e+00]\n  [-1.7366698e+00 -3.2977620e-01 -4.6010923e-02  1.4402350e+00\n    1.3192053e+00  1.3484259e+00]]\n\n [[ 7.1757758e-01 -5.3470486e-01  1.3439754e+00  2.0178527e-01\n   -6.7014891e-01 -6.9064277e-01]\n  [ 4.9495730e-01  8.0118150e-01  1.3559695e+00  1.5868064e-02\n   -6.8020791e-01 -7.0018387e-01]\n  [ 1.7490159e-01  1.3862749e+00  1.3439754e+00 -1.7004915e-01\n   -6.9026929e-01 -7.0971996e-01]\n  ...\n  [ 2.7108523e-01 -6.8999356e-01 -1.2601614e+00 -6.9631565e-01\n   -8.8190097e-01 -8.8995004e-01]\n  [ 8.9671634e-02 -1.3650225e-01 -1.3412718e+00 -5.2921379e-01\n   -8.9201117e-01 -8.9938539e-01]\n  [-1.3918757e-02 -3.0863822e-01 -1.4002198e+00 -3.5278544e-01\n   -9.0212387e-01 -9.0881574e-01]]\n\n [[-1.2862133e+00 -1.0885423e-01  9.4533908e-01 -9.9131155e-01\n    1.1471704e+00  1.1595349e+00]\n  [-1.4420683e+00 -3.2772058e-01  8.0746084e-01 -1.1141583e+00\n    1.1375873e+00  1.1490865e+00]\n  [-1.5463889e+00 -4.9654108e-01  6.5497947e-01 -1.2176700e+00\n    1.1280016e+00  1.1386427e+00]\n  ...\n  [-5.9488040e-01 -2.4102142e-01 -1.3412719e+00  5.6094950e-01\n    9.4536269e-01  9.4112182e-01]\n  [-2.7565923e-01  1.0982010e+00 -1.2601615e+00  7.2805136e-01\n    9.3572342e-01  9.3077397e-01]\n  [-3.3282694e-01  3.9680892e-01 -1.1582767e+00  8.8296759e-01\n    9.2608148e-01  9.2043102e-01]]\n\n ...\n\n [[-2.3080339e+00  3.1764600e+00 -1.4359970e+00 -1.7004934e-01\n    1.4429069e+00  1.4858066e+00]\n  [-2.3323405e+00  5.7863545e-01 -1.4479913e+00  1.5867855e-02\n    1.4334077e+00  1.4752103e+00]\n  [-2.3130412e+00  1.0020280e+00 -1.4359971e+00  2.0178506e-01\n    1.4239057e+00  1.4646188e+00]\n  ...\n  [-1.7819449e+00 -3.1186965e-01  1.1681397e+00  7.2805154e-01\n    1.2428534e+00  1.2642835e+00]\n  [-1.8306626e+00 -3.8118464e-01  1.2492502e+00  5.6094968e-01\n    1.2332972e+00  1.2537872e+00]\n  [-1.8734341e+00  1.3253057e-01  1.3081982e+00  3.8452137e-01\n    1.2237383e+00  1.2432956e+00]]\n\n [[ 1.4384332e+00  7.1043867e-01  1.3081982e+00 -3.5278526e-01\n    2.5443134e-01  2.1846443e-01]\n  [ 1.3752148e+00 -4.7947538e-01  1.2492502e+00 -5.2921361e-01\n    2.4460618e-01  2.0846164e-01]\n  [ 1.4601319e+00 -5.7056773e-01  1.1681398e+00 -6.9631547e-01\n    2.3477846e-01  1.9846375e-01]\n  ...\n  [ 8.2262844e-01 -2.5105473e-01 -1.4359970e+00 -1.7004934e-01\n    4.7564637e-02  9.4377464e-03]\n  [ 9.1463923e-01 -7.1157187e-01 -1.4479913e+00  1.5867855e-02\n    3.7685726e-02 -4.6175241e-04]\n  [ 8.8073504e-01 -7.8804970e-01 -1.4359971e+00  2.0178506e-01\n    2.7804270e-02 -1.0356318e-02]]\n\n [[ 9.1463923e-01 -7.1157187e-01 -1.4479913e+00  1.5867855e-02\n    3.7685726e-02 -4.6175241e-04]\n  [ 8.8073504e-01 -7.8804970e-01 -1.4359971e+00  2.0178506e-01\n    2.7804270e-02 -1.0356318e-02]\n  [ 9.1443062e-01 -8.3035409e-01 -1.4002199e+00  3.8452116e-01\n    1.7920269e-02 -2.0245951e-02]\n  ...\n  [ 5.1456958e-01 -5.1052535e-01  1.2492502e+00  5.6094968e-01\n   -1.7035760e-01 -2.0720980e-01]\n  [ 6.5373331e-01 -7.5144726e-01  1.3081982e+00  3.8452137e-01\n   -1.8029223e-01 -2.1700047e-01]\n  [ 5.8498603e-01 -8.0212516e-01  1.3439754e+00  2.0178527e-01\n   -1.9022939e-01 -2.2678620e-01]]]\n7\n[[[-1.1978537  -0.00803327  1.1681398  -0.69631547  1.6228718\n    1.6880344 ]\n  [-1.3034261   0.7461442   1.0662551  -0.85123163  1.6134245\n    1.6773484 ]\n  [-1.5226039   1.024915    0.9453391  -0.99131155  1.6039746\n    1.666667  ]\n  ...\n  [-2.3130412   1.002028   -1.4359971   0.20178506  1.4239057\n    1.4646188 ]\n  [-2.4075558   0.52693075 -1.4002199   0.38452116  1.414401\n    1.4540321 ]\n  [-2.2865438   0.36355424 -1.3412719   0.5609495   1.4048938\n    1.4434501 ]]\n\n [[-2.1109722   0.17391069 -1.0373607   1.0230474   1.3763554\n    1.4117326 ]\n  [-1.6532133   0.952873   -0.8994825   1.1458942   1.3668371\n    1.4011695 ]\n  [-1.7467889   0.3658436  -0.7470011   1.249406    1.3573161\n    1.3906113 ]\n  ...\n  [-1.4915162   0.53435975  1.2492502  -0.5292136   1.1759036\n    1.1909094 ]\n  [-1.3015484   0.6104904   1.1681398  -0.69631547  1.1663285\n    1.1804465 ]\n  [-1.3265853   0.4784688   1.0662551  -0.85123163  1.1567509\n    1.1699883 ]]\n\n [[-0.33282694  0.39680892 -1.1582767   0.8829676   0.9260815\n    0.920431  ]\n  [-0.24123342 -0.03693422 -1.0373607   1.0230474   0.91643685\n    0.91009283]\n  [ 0.12514065  0.9244569  -0.8994825   1.1458942   0.9067896\n    0.8997595 ]\n  ...\n  [ 1.2296876   1.2971247   1.3081982  -0.35278526  0.7229882\n    0.7043426 ]\n  [ 1.242832    1.6743234   1.2492502  -0.5292136   0.713288\n    0.6941058 ]\n  [ 1.25003     1.1540617   1.1681398  -0.69631547  0.7035852\n    0.6838739 ]]\n\n ...\n\n [[-0.02591563 -0.7866666   1.1681398  -0.69631547 -1.2066257\n   -1.1893727 ]\n  [-0.14974423 -0.64377695  1.0662551  -0.85123163 -1.2168128\n   -1.198646  ]\n  [-0.16309726 -0.45592242  0.9453391  -0.99131155 -1.2270025\n   -1.2079141 ]\n  ...\n  [-0.6572641  -0.7184204  -1.4359971   0.20178506 -1.4210569\n   -1.3830411 ]\n  [-0.61094576 -0.87760746 -1.4002199   0.38452116 -1.431294\n   -1.3922074 ]\n  [-0.734983   -0.77563095 -1.3412719   0.5609495  -1.4415334\n   -1.4013684 ]]\n\n [[-0.73122746  0.15256436 -1.435997   -0.17004934  0.98389316\n    0.98256105]\n  [-0.70139176  0.03917193 -1.4479913   0.01586786  0.9742645\n    0.972194  ]\n  [-0.5894557   0.33136463 -1.4359971   0.20178506  0.9646332\n    0.9618318 ]\n  ...\n  [ 0.6569673   0.6627974   1.1681397   0.72805154  0.7811339\n    0.7658648 ]\n  [ 0.58404714  1.8092033   1.2492502   0.5609497   0.7714495\n    0.75559896]\n  [ 0.8619573   1.1748642   1.3081982   0.38452137  0.76176256\n    0.745338  ]]\n\n [[-0.11010239 -0.43235826  0.3168485  -1.3599648  -0.78093237\n   -0.79531866]\n  [-0.23768653 -0.1716705   0.13698444 -1.3963134  -0.79101825\n   -0.8048045 ]\n  [-0.3775805   0.4133694  -0.04601072 -1.408499   -0.8011066\n   -0.8142853 ]\n  ...\n  [-0.2744074  -0.00381959 -0.8994825   1.1458942  -0.9932468\n   -0.9934615 ]\n  [-0.18740398 -0.39982814 -0.7470011   1.249406   -1.0033836\n   -1.0028412 ]\n  [-0.14494547 -0.54754376 -0.58252555  1.3318114  -1.0135229\n   -1.012216  ]]]\n8\n[[[ 0.64674383 -0.86104244 -1.4479913   0.01586786 -0.43947282\n   -0.46981344]\n  [ 0.6657302  -0.85704416 -1.4359971   0.20178506 -0.449475\n   -0.47946972]\n  [ 0.67418015 -0.9377253  -1.4002199   0.38452116 -0.45947966\n   -0.48912105]\n  ...\n  [ 0.8893936  -0.07955428  1.2492502   0.5609497  -0.65003836\n   -0.67154545]\n  [ 0.6908715   0.13741085  1.3081982   0.38452137 -0.6600924\n   -0.6810966 ]\n  [ 0.7175776  -0.53470486  1.3439754   0.20178527 -0.6701489\n   -0.6906428 ]]\n\n [[-1.5226039   1.024915    0.9453391  -0.99131155  1.6039746\n    1.666667  ]\n  [-1.5025742   1.2226775   0.80746084 -1.1141583   1.594522\n    1.6559904 ]\n  [-1.6282806  -0.03992936  0.65497947 -1.21767     1.5850666\n    1.6453184 ]\n  ...\n  [-2.2865438   0.36355424 -1.3412719   0.5609495   1.4048938\n    1.4434501 ]\n  [-2.340895    0.0219566  -1.2601615   0.72805136  1.3953837\n    1.4328729 ]\n  [-2.227394   -0.04931745 -1.1582767   0.8829676   1.3858709\n    1.4223003 ]]\n\n [[ 0.90869296  0.2074684   0.49050394 -1.3000755   0.18560132\n    0.14854796]\n  [ 1.0419104  -0.16326058  0.3168485  -1.3599648   0.17575818\n    0.13857953]\n  [ 0.9901674  -0.27041173  0.13698444 -1.3963134   0.1659125\n    0.12861602]\n  ...\n  [ 0.97650135 -0.51366466 -1.0373607   1.0230474  -0.02164116\n   -0.05975511]\n  [ 0.900243   -0.94054365 -0.8994825   1.1458942  -0.03153786\n   -0.06962005]\n  [ 0.99360996 -0.97399396 -0.7470011   1.249406   -0.04143711\n   -0.07948005]]\n\n ...\n\n [[ 0.7249843   1.3630369  -1.1582766  -0.8512318   0.55772793\n    0.5309773 ]\n  [ 0.9335213   1.3316437  -1.2601614  -0.69631565  0.54798317\n    0.5208231 ]\n  [ 1.1496736   2.0395422  -1.3412718  -0.5292138   0.5382358\n    0.5106737 ]\n  ...\n  [ 1.039198   -0.32780138  0.6549793   1.249406    0.35254103\n    0.31876191]\n  [ 1.272772    0.79352576  0.80746067  1.1458944   0.34274167\n    0.30871013]\n  [ 1.1385113  -0.11146946  0.94533896  1.0230476   0.33293974\n    0.29866323]]\n\n [[ 0.04470944 -0.03702861  0.9453391  -0.99131155 -0.7406132\n   -0.7573251 ]\n  [-0.37424225  2.2467246   0.80746084 -1.1141583  -0.7506893\n   -0.76683104]\n  [-0.09612342  0.9577609   0.65497947 -1.21767    -0.7607679\n   -0.77633196]\n  ...\n  [ 0.11168329 -0.6656788  -1.3412719   0.5609495  -0.9527235\n   -0.9558917 ]\n  [ 0.11762957 -0.78556186 -1.2601615   0.72805136 -0.9628507\n   -0.96529174]\n  [ 0.13066964 -0.7719391  -1.1582767   0.8829676  -0.9729803\n   -0.97468674]]\n\n [[ 0.10166851 -0.33996418 -1.435997   -0.17004934 -0.91223896\n   -0.918241  ]\n  [ 0.10417221 -1.0012401  -1.4479913   0.01586786 -0.9223564\n   -0.9276613 ]\n  [ 0.02551444 -0.7348803  -1.4359971   0.20178506 -0.93247634\n   -0.9370765 ]\n  ...\n  [ 0.16968556 -0.9136203   1.1681397   0.72805154 -1.1252137\n   -1.1150037 ]\n  [ 0.21767306 -0.7784192   1.2492502   0.5609497  -1.1353818\n   -1.1243176 ]\n  [-0.01903047 -0.612788    1.3081982   0.38452137 -1.1455524\n   -1.1336265 ]]]\n9\n[[[-3.77580494e-01  4.13369387e-01 -4.60107177e-02 -1.40849900e+00\n   -8.01106572e-01 -8.14285278e-01]\n  [ 4.42921594e-02  6.24793589e-01 -2.29005873e-01 -1.39631343e+00\n   -8.11197340e-01 -8.23760986e-01]\n  [ 1.80430591e-01  4.47886497e-01 -4.08869952e-01 -1.35996497e+00\n   -8.21290553e-01 -8.33231688e-01]\n  ...\n  [-1.44945472e-01 -5.47543764e-01 -5.82525551e-01  1.33181143e+00\n   -1.01352286e+00 -1.01221597e+00]\n  [-9.20549110e-02 -9.26260710e-01 -4.08870131e-01  1.39170086e+00\n   -1.02366459e+00 -1.02158570e+00]\n  [-3.14446241e-02 -9.32844043e-01 -2.29006082e-01  1.42804933e+00\n   -1.03380871e+00 -1.03095031e+00]]\n\n [[ 5.84047139e-01  1.80920327e+00  1.24925017e+00  5.60949683e-01\n    7.71449506e-01  7.55598962e-01]\n  [ 8.61957312e-01  1.17486417e+00  1.30819821e+00  3.84521365e-01\n    7.61762559e-01  7.45338023e-01]\n  [ 8.93462121e-01  3.97551447e-01  1.34397542e+00  2.01785266e-01\n    7.52072871e-01  7.35081911e-01]\n  ...\n  [ 8.54133248e-01  1.17857862e+00 -1.03736055e+00 -9.91311669e-01\n    5.67470074e-01  5.41136444e-01]\n  [ 7.24984288e-01  1.36303687e+00 -1.15827656e+00 -8.51231813e-01\n    5.57727933e-01  5.30977309e-01]\n  [ 9.33521271e-01  1.33164370e+00 -1.26016140e+00 -6.96315646e-01\n    5.47983170e-01  5.20823121e-01]]\n\n [[-1.54065132e+00  7.80226365e-02  3.16848487e-01 -1.35996485e+00\n    1.56614757e+00  1.62398863e+00]\n  [-1.50163531e+00 -4.78617400e-01  1.36984438e-01 -1.39631343e+00\n    1.55668390e+00  1.61333084e+00]\n  [-1.61263251e+00 -7.93173492e-01 -4.60107177e-02 -1.40849900e+00\n    1.54721749e+00  1.60267782e+00]\n  ...\n  [-1.65321326e+00  9.52872992e-01 -8.99482489e-01  1.14589417e+00\n    1.36683714e+00  1.40116954e+00]\n  [-1.74678886e+00  3.65843594e-01 -7.47001112e-01  1.24940598e+00\n    1.35731614e+00  1.39061129e+00]\n  [-1.61962199e+00  2.66500860e-01 -5.82525551e-01  1.33181143e+00\n    1.34779251e+00  1.38005781e+00]]\n\n ...\n\n [[ 1.09187996e+00 -2.60870576e-01  1.24925017e+00  5.60949683e-01\n    3.03518444e-01  2.68551946e-01]\n  [ 1.12797499e+00 -4.30525422e-01  1.30819821e+00  3.84521365e-01\n    2.93706179e-01  2.58524626e-01]\n  [ 1.20558953e+00 -4.60071862e-01  1.34397542e+00  2.01785266e-01\n    2.83891320e-01  2.48502240e-01]\n  ...\n  [ 9.17664528e-01 -3.01482469e-01 -1.03736055e+00 -9.91311669e-01\n    9.69209522e-02  5.90091869e-02]\n  [ 7.96652615e-01 -2.01493248e-01 -1.15827656e+00 -8.51231813e-01\n    8.70547891e-02  4.90850434e-02]\n  [ 8.74371469e-01 -5.84120512e-01 -1.26016140e+00 -6.96315646e-01\n    7.71860778e-02  3.91658247e-02]]\n\n [[ 9.17664528e-01 -3.01482469e-01 -1.03736055e+00 -9.91311669e-01\n    9.69209522e-02  5.90091869e-02]\n  [ 7.96652615e-01 -2.01493248e-01 -1.15827656e+00 -8.51231813e-01\n    8.70547891e-02  4.90850434e-02]\n  [ 8.74371469e-01 -5.84120512e-01 -1.26016140e+00 -6.96315646e-01\n    7.71860778e-02  3.91658247e-02]\n  ...\n  [ 7.69737840e-01 -2.59009302e-01  4.90503758e-01  1.33181155e+00\n   -1.10802755e-01 -1.48361579e-01]\n  [ 5.13317764e-01  5.08236110e-01  6.54979289e-01  1.24940598e+00\n   -1.20722249e-01 -1.58182010e-01]\n  [ 5.48369467e-01 -1.06843181e-01  8.07460666e-01  1.14589441e+00\n   -1.30644277e-01 -1.67997479e-01]]\n\n [[ 1.00675440e+00 -5.05675018e-01 -7.47001112e-01  1.24940598e+00\n    4.30842608e-01  3.99352163e-01]\n  [ 1.11503923e+00 -1.18707821e-01 -5.82525551e-01  1.33181143e+00\n    4.21063989e-01  3.89261276e-01]\n  [ 1.08655965e+00 -1.19308919e-01 -4.08870131e-01  1.39170086e+00\n    4.11282778e-01  3.79175276e-01]\n  ...\n  [ 1.23678136e+00  1.09894490e+00  1.06625509e+00 -8.51231635e-01\n    2.24948168e-01  1.88470781e-01]\n  [ 1.17387605e+00 -6.53544033e-04  9.45339084e-01 -9.91311550e-01\n    2.15115309e-01  1.78482711e-01]\n  [ 1.13569462e+00  1.89106256e-01  8.07460845e-01 -1.11415827e+00\n    2.05279887e-01  1.68499544e-01]]]\n10\n[[[-2.33234048e+00  5.78635454e-01 -1.44799125e+00  1.58678554e-02\n    1.43340766e+00  1.47521031e+00]\n  [-2.31304121e+00  1.00202799e+00 -1.43599713e+00  2.01785058e-01\n    1.42390573e+00  1.46461880e+00]\n  [-2.40755582e+00  5.26930749e-01 -1.40021992e+00  3.84521157e-01\n    1.41440105e+00  1.45403206e+00]\n  ...\n  [-1.83066261e+00 -3.81184638e-01  1.24925017e+00  5.60949683e-01\n    1.23329723e+00  1.25378716e+00]\n  [-1.87343407e+00  1.32530570e-01  1.30819821e+00  3.84521365e-01\n    1.22373831e+00  1.24329555e+00]\n  [-1.74209440e+00 -2.23076850e-01  1.34397542e+00  2.01785266e-01\n    1.21417677e+00  1.23280883e+00]]\n\n [[ 9.76501346e-01 -5.13664663e-01 -1.03736067e+00  1.02304745e+00\n   -2.16411594e-02 -5.97551093e-02]\n  [ 9.00242984e-01 -9.40543652e-01 -8.99482489e-01  1.14589417e+00\n   -3.15378644e-02 -6.96200505e-02]\n  [ 9.93609965e-01 -9.73993957e-01 -7.47001112e-01  1.24940598e+00\n   -4.14371081e-02 -7.94800520e-02]\n  ...\n  [ 6.77935719e-01 -8.83000314e-01  1.24925017e+00 -5.29213607e-01\n   -2.30003133e-01 -2.65879452e-01]\n  [ 6.76683843e-01 -9.58728254e-01  1.16813982e+00 -6.96315467e-01\n   -2.39952862e-01 -2.75640368e-01]\n  [ 7.65356421e-01 -5.26156783e-01  1.06625509e+00 -8.51231635e-01\n   -2.49905095e-01 -2.85396308e-01]]\n\n [[ 1.23636413e+00  5.67755699e+00  1.36984244e-01  1.42804933e+00\n    8.48850310e-01  8.37860584e-01]\n  [ 1.08165658e+00  2.80534816e+00  3.16848308e-01  1.39170086e+00\n    8.39184463e-01  8.27560961e-01]\n  [ 7.98947632e-01  2.12599254e+00  4.90503758e-01  1.33181155e+00\n    8.29515994e-01  8.17266226e-01]\n  ...\n  [ 5.01007915e-01  2.59741545e+00  3.16848487e-01 -1.35996485e+00\n    6.45313084e-01  6.22584224e-01]\n  [ 6.32451892e-01  1.53279686e+00  1.36984438e-01 -1.39631343e+00\n    6.35591924e-01  6.12386227e-01]\n  [ 4.30591464e-01  1.26537800e+00 -4.60107177e-02 -1.40849900e+00\n    6.25868082e-01  6.02193117e-01]]\n\n ...\n\n [[ 1.12286317e+00 -6.84007645e-01 -4.60107177e-02 -1.40849900e+00\n    1.56064242e-01  1.18657432e-01]\n  [ 1.21414375e+00 -9.77411345e-02 -2.29005873e-01 -1.39631343e+00\n    1.46213412e-01  1.08703755e-01]\n  [ 1.24658751e+00 -5.86120307e-01 -4.08869952e-01 -1.35996497e+00\n    1.36360034e-01  9.87550020e-02]\n  ...\n  [ 1.07925725e+00 -9.31705713e-01 -5.82525551e-01  1.33181143e+00\n   -5.13388887e-02 -8.93351138e-02]\n  [ 1.06246161e+00 -9.93867159e-01 -4.08870131e-01  1.39170086e+00\n   -6.12432063e-02 -9.91852209e-02]\n  [ 1.07842267e+00 -7.94777632e-01 -2.29006082e-01  1.42804933e+00\n   -7.11500496e-02 -1.09030388e-01]]\n\n [[ 1.30669639e-01 -7.71939099e-01 -1.15827668e+00  8.82967591e-01\n   -9.72980320e-01 -9.74686742e-01]\n  [-8.66302401e-02 -7.37081051e-01 -1.03736067e+00  1.02304745e+00\n   -9.83112335e-01 -9.84076619e-01]\n  [-2.74407387e-01 -3.81959439e-03 -8.99482489e-01  1.14589417e+00\n   -9.93246794e-01 -9.93461490e-01]\n  ...\n  [ 6.52606040e-02 -9.75235939e-01  1.30819821e+00 -3.52785259e-01\n   -1.18625832e+00 -1.17081094e+00]\n  [ 3.44860181e-02 -9.90260959e-01  1.24925017e+00 -5.29213607e-01\n   -1.19644082e+00 -1.18009436e+00]\n  [-2.59156302e-02 -7.86666572e-01  1.16813982e+00 -6.96315467e-01\n   -1.20662570e+00 -1.18937266e+00]]\n\n [[ 5.74866891e-01  3.91484737e-01 -4.60109226e-02  1.44023502e+00\n    8.58513474e-01  8.48165035e-01]\n  [ 1.23636413e+00  5.67755699e+00  1.36984244e-01  1.42804933e+00\n    8.48850310e-01  8.37860584e-01]\n  [ 1.08165658e+00  2.80534816e+00  3.16848308e-01  1.39170086e+00\n    8.39184463e-01  8.27560961e-01]\n  ...\n  [ 4.38728482e-01  2.55078769e+00  4.90503937e-01 -1.30007553e+00\n    6.55031681e-01  6.32787049e-01]\n  [ 5.01007915e-01  2.59741545e+00  3.16848487e-01 -1.35996485e+00\n    6.45313084e-01  6.22584224e-01]\n  [ 6.32451892e-01  1.53279686e+00  1.36984438e-01 -1.39631343e+00\n    6.35591924e-01  6.12386227e-01]]]\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for element in single_step_window.train[0]:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    print(element.numpy())\n",
    "    if len(element.numpy()) < 32:\n",
    "        break\n",
    "    if count == 1:\n",
    "        train_input = element.numpy()\n",
    "    else:\n",
    "        train_input = np.append(train_input, element.numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(288, 24, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1\n(32, 1, 1)\n2\n(32, 1, 1)\n3\n(32, 1, 1)\n4\n(32, 1, 1)\n5\n(32, 1, 1)\n6\n(32, 1, 1)\n7\n(32, 1, 1)\n8\n(32, 1, 1)\n9\n(32, 1, 1)\n10\n(15, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for element in single_step_window.train[1]:\n",
    "    count += 1\n",
    "    print(count)\n",
    "    print(element.numpy().shape)\n",
    "    if len(element.numpy()) < 32:\n",
    "        break\n",
    "    if count == 1:\n",
    "        train_label = element.numpy()\n",
    "    else:\n",
    "        train_label = np.append(train_label, element.numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(288, 1, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main model ###\n",
    "# linear module\n",
    "linear_input = tf.keras.Input(shape=(single_step_window.example[0].shape[1:]), batch_size=single_step_window.example[0].shape[0])  # batch 32 input shape = 24,6\n",
    "x = tf.keras.layers.Flatten()(linear_input)\n",
    "x = tf.keras.layers.Dense(units=128, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(units=1, activation='relu')(x)\n",
    "linear_model = tf.keras.Model(inputs=linear_input, outputs=x)  # output = 32,1\n",
    "\n",
    "# lstm module\n",
    "lstm_input = tf.keras.Input(shape=(single_step_window.example[0].shape[1:]), batch_size=single_step_window.example[0].shape[0])\n",
    "y = tf.keras.layers.LSTM(32, return_sequences=False)(lstm_input)\n",
    "y = tf.keras.layers.Dense(units=1, activation='relu')(y)\n",
    "lstm_model = tf.keras.Model(inputs=lstm_input, outputs=y)  # output = 32,1\n",
    "\n",
    "# intersection\n",
    "z = tf.keras.layers.concatenate([linear_model.output, lstm_model.output])\n",
    "z = tf.keras.layers.Dense(units=64, activation='relu')(z)\n",
    "z = tf.keras.layers.Dense(units=1, activation='relu')(z)\n",
    "comb_model = tf.keras.Model(inputs=[linear_input, lstm_input], outputs=[z])\n",
    "\n",
    "\n",
    "# training setting\n",
    "\n",
    "MAX_EPOCHS = 20\n",
    "\n",
    "def compile_and_fit(model, window, patience=2):\n",
    "  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "\n",
    "  model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "  history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping])\n",
    "  return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(comb_model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_5\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(32, 24, 6)]        0                                            \n__________________________________________________________________________________________________\nflatten (Flatten)               (32, 144)            0           input_1[0][0]                    \n__________________________________________________________________________________________________\ndense (Dense)                   (32, 128)            18560       flatten[0][0]                    \n__________________________________________________________________________________________________\ninput_2 (InputLayer)            [(32, 24, 6)]        0                                            \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (32, 64)             8256        dense[0][0]                      \n__________________________________________________________________________________________________\nlstm (LSTM)                     (32, 32)             4992        input_2[0][0]                    \n__________________________________________________________________________________________________\ndense_2 (Dense)                 (32, 1)              65          dense_1[0][0]                    \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (32, 1)              33          lstm[0][0]                       \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (32, 2)              0           dense_2[0][0]                    \n                                                                 dense_3[0][0]                    \n__________________________________________________________________________________________________\ndense_4 (Dense)                 (32, 64)             192         concatenate[0][0]                \n__________________________________________________________________________________________________\ndense_5 (Dense)                 (32, 1)              65          dense_4[0][0]                    \n==================================================================================================\nTotal params: 32,163\nTrainable params: 32,163\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=2,\n",
    "                                                mode='min')\n",
    "comb_model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "comb_model.summary()\n",
    "\n",
    "\n",
    "# define val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6349 - mean_absolute_error: 0.6867\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.6120 - mean_absolute_error: 0.6681\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5610 - mean_absolute_error: 0.6374\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5466 - mean_absolute_error: 0.6187\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5298 - mean_absolute_error: 0.6020\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.5209 - mean_absolute_error: 0.5997\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.5064 - mean_absolute_error: 0.5965\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4993 - mean_absolute_error: 0.5812\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4882 - mean_absolute_error: 0.5763\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4739 - mean_absolute_error: 0.5561\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4561 - mean_absolute_error: 0.5525\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4308 - mean_absolute_error: 0.5231\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4261 - mean_absolute_error: 0.5242\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.4134 - mean_absolute_error: 0.5136\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.4034 - mean_absolute_error: 0.4986\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3981 - mean_absolute_error: 0.4969\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3860 - mean_absolute_error: 0.4862\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3757 - mean_absolute_error: 0.4705\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3789 - mean_absolute_error: 0.4781\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.3758 - mean_absolute_error: 0.4775\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24eaa321688>"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# training\n",
    "comb_model.fit([train_input, train_input], [train_label], epochs=MAX_EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "val_performance['multi_modal'] = comb_model.evaluate([train_input, train_input], [train_label])\n",
    "performance['multi_modal'] = comb_model.evaluate([train_input, train_input], [train_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(x = range(len(train_df.columns)),\n",
    "        height=lstm_model.layers[0].kernel[:,0].numpy())\n",
    "axis = plt.gca()\n",
    "axis.set_xticks(range(len(train_df.columns)))\n",
    "_ = axis.set_xticklabels(train_df.columns, rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input shape:', wide_window.example[0].shape)\n",
    "print('Output shape:', linear(wide_window.example[0]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}